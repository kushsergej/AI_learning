{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d16d64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['How', 'Ġto', 'Ġwrite', 'Ġa', 'Ġunit', 'Ġtests', 'Ġon', 'ĠPython', 'Ġproject', 'Use', 'ĠPy', 'Test', 'Ġand', 'ĠSpark']\n",
      "ids: [4438, 311, 3350, 264, 5089, 7177, 389, 13325, 2447, 10464, 5468, 2323, 323, 27565]\n",
      "summary: {'input_ids': [[4438, 311, 3350, 264, 5089, 7177, 389, 13325, 2447], [10464, 5468, 2323, 323, 27565]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1]]}\n",
      "decoded: How to write a unit tests on Python projectUse PyTest and Spark\n",
      "[{'generated_text': \"How to write a unit tests on Python project?\\nWhen writing unit tests for a Python project, it's essential to follow a structured approach. Here's a step-by-step guide to help you write effective unit tests:\\n\\n1. Define the test cases:\\n   - Identify the functionalities you want to test.\\n   - Determine the input and expected output for each functionality.\\n   - Create a test case for each functionality, including the input, expected output, and any assertions.\\n\\n2. Use the right test framework:\\n   - Select a suitable testing framework based on your project's requirements (e.g., unittest, pytest).\\n   - Choose the appropriate test method for your test case (e.g., assertEqual, assertNotEqual, assertIn).\\n\\n3. Write clear and concise assertions:\\n   - Use meaningful and descriptive names for your assertions.\\n   - Ensure that the assertions are clear and follow the language's syntax.\\n   - Use the appropriate assertion types based on the expected result.\\n\\n4. Handle edge cases:\\n   - Test your code under different scenarios, including edge cases.\\n   - Verify that your assertions correctly handle special cases and boundary conditions.\\n\\n5. Test with different input scenarios:\\n   - Test your code with various input values, including empty strings, special characters, large numbers, and negative numbers.\\n   - Ensure that your assertions\"}]\n",
      "[{'generated_text': 'Use PyTest and Spark are two popular testing frameworks for Python. Both are designed to be easy to use and have a large ecosystem of libraries and packages to help with testing. Here are some key differences between the two:\\n\\n1. Framework: \\n- Test-Driven Development (TDD) is the approach of writing tests before writing the actual code. TDD is a popular approach in the software development industry.\\n- Spark is a powerful open-source data processing framework for big data and machine learning. It is designed to be scalable, fault-tolerant, and easy to use for building distributed systems.\\n\\n2. Testing Approach:\\n- Test-Driven Development (TDD) is a testing approach that involves writing tests before writing the actual code. It is a common approach in the software development industry.\\n- Spark is a data processing framework that provides a collection of APIs for processing large datasets, performing machine learning, and building distributed systems. It is designed to be scalable, fault-tolerant, and easy to use for building distributed systems.\\n\\n3. Tooling and Libraries:\\n- Test-Driven Development (TDD) is a tooling approach that involves writing tests before writing the actual code. It is a common approach in the software development industry.\\n- Spark is a set of APIs for processing large datasets,'}]\n"
     ]
    }
   ],
   "source": [
    "# Hugginface playground\n",
    "\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "login(token=os.getenv('HF_READ_TOKEN'))\n",
    "model_id = 'ibm-granite/granite-4.0-h-350m'\n",
    "\n",
    "# ls -la /c/Users/Siarhei_Kushniaruk/.cache/huggingface\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to('cpu')\n",
    "model.eval()\n",
    "\n",
    "chat = [\n",
    "    'How to write a unit tests on Python project',\n",
    "    'Use PyTest and Spark'\n",
    "]\n",
    "print(f'tokens: {tokenizer.tokenize(chat)}')\n",
    "print(f'ids: {tokenizer.convert_tokens_to_ids(tokenizer.tokenize(chat))}')\n",
    "print(f'summary: {tokenizer(chat)}')\n",
    "print(f'decoded: {tokenizer.decode(tokenizer.convert_tokens_to_ids(tokenizer.tokenize(chat)))}')\n",
    "\n",
    "pipe = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "res = pipe(chat, temperature=0.8, top_p=0.9)\n",
    "for message in res:\n",
    "    print(message[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3046c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sigmoid function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function\n",
    "x = np.linspace(-10, 10, 400)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, linewidth=2)\n",
    "plt.title(r'Plot of $f(x) = \\frac{1}{1 + e^{-x}}$ (Sigmoid Function)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA fine-tuning\n",
    "\n",
    "import hf_xet\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "from datasets import load_dataset\n",
    "\n",
    "try:\n",
    "    print('>>> Load LLM')\n",
    "    model_name = 'gpt2'\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map='auto')\n",
    "\n",
    "    peft_config = LoraConfig(\n",
    "        task_type=TaskType.CAUSAL_LM,\n",
    "        inference_mode=False,\n",
    "        fan_in_fan_out=True,\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05\n",
    "    )\n",
    "    model = get_peft_model(model, peft_config)\n",
    "\n",
    "    def tokenize_fn(examples):\n",
    "        return tokenizer(examples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "\n",
    "    print('>>> Tokenize loaded datasets')\n",
    "    dataset = load_dataset('mteb/tweet_sentiment_extraction')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenized_datasets = dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./LoRA_output',\n",
    "        per_device_train_batch_size=4,\n",
    "        num_train_epochs=3,\n",
    "        save_steps=100,\n",
    "        seed=42,\n",
    "        fp16=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        dataloader_num_workers=0\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        processing_class=tokenizer,\n",
    "        train_dataset=tokenized_datasets['train']\n",
    "    )\n",
    "\n",
    "    print('>>> Training')\n",
    "    trainer.train()\n",
    "\n",
    "    print('>>> Validating')\n",
    "    trainer.evaluate()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ce363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GGUF quantization\n",
    "\n",
    "\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.quantization as quant\n",
    "\n",
    "# Step 1: Define a simple neural network model in PyTorch\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(50, 20)  # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(20, 5)   # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))   # ReLU activation after first layer\n",
    "        x = torch.relu(self.fc2(x))   # ReLU activation after second layer\n",
    "        x = self.fc3(x)               # Output layer\n",
    "        return x\n",
    "\n",
    "# Step 2: Initialize the model and switch to evaluation mode\n",
    "model = SimpleModel()\n",
    "model.eval()\n",
    "\n",
    "\n",
    "torch.save(model, './LLMs/simple_model.pth')\n",
    "\n",
    "quantized_model = torch.ao.quantization.quantize_dynamic(\n",
    "    model, {nn.Linear},\n",
    "    dtype=torch.qint8\n",
    ")\n",
    "torch.save(quantized_model, './LLMs/quantized_simple_model.pth')\n",
    "\n",
    "\n",
    "dummy_input = torch.randn(1, 10)\n",
    "print('Dummy input', dummy_input)\n",
    "print('Model output:', model(dummy_input))\n",
    "print('Quantized model output:', quantized_model(dummy_input))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
