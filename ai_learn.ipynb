{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df29563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interact with LLM via API authn\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "try:\n",
    "    # This will tell you if your API key is valid and show account info\n",
    "    models = client.models.list()\n",
    "    print(f\"Available models: {len(models.data)}\")\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful DevOps assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Explain how CI/CD works in Azure DevOps.\"}\n",
    "        ]\n",
    "    )\n",
    "    print(response.choices[0].message.content)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3046c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot sigmoid function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the function\n",
    "x = np.linspace(-10, 10, 400)\n",
    "y = 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(x, y, linewidth=2)\n",
    "plt.title(r\"Plot of $f(x) = \\frac{1}{1 + e^{-x}}$ (Sigmoid Function)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde1e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning\n",
    "\n",
    "import torch\n",
    "import evaluate\n",
    "import hf_xet\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2ForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "try:\n",
    "    dataset = load_dataset('mteb/tweet_sentiment_extraction')\n",
    "    df_train = pd.DataFrame(dataset['train'])\n",
    "    df_test = pd.DataFrame(dataset['test'])\n",
    "\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    def tokenize(examples):\n",
    "        return tokenizer(examples['text'], padding='max_length', truncation=True)\n",
    "    tokenized_datasets = dataset.map(tokenize, batched=True)\n",
    "    small_train_dataset = tokenized_datasets['train'].shuffle(seed=42).select(range(1000))\n",
    "    small_eval_dataset = tokenized_datasets['test'].shuffle(seed=42).select(range(1000))\n",
    "\n",
    "    model = GPT2ForSequenceClassification.from_pretrained('gpt2', num_labels=3)\n",
    "\n",
    "    metric = evaluate.load('accuracy')\n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"test_trainer\",\n",
    "        #evaluation_strategy=\"epoch\",\n",
    "        per_device_train_batch_size=1,  # Reduce batch size here\n",
    "        per_device_eval_batch_size=1,    # Optionally, reduce for evaluation as well\n",
    "        gradient_accumulation_steps=4\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=small_train_dataset,\n",
    "        eval_dataset=small_eval_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.evaluate()\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
